{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPMG34N-WPGx",
        "outputId": "b2b2a0c8-0a3e-4931-f87c-409a84a93039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "_DnThwzuX9Ft"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path dataset\n",
        "data_dir = '/content/drive/My Drive/Sharer.pw/data'\n",
        "bs= 32\n",
        "\n",
        "# Transformasi untuk augmentasi dan normalisasi\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),       # Mengubah ukuran gambar menjadi 128x128\n",
        "    transforms.ToTensor(),               # Mengubah gambar menjadi tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalisasi nilai RGB\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),       # Mengubah ukuran gambar menjadi 224x224 untuk validasi\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Dataset dengan ImageFolder\n",
        "full_dataset = datasets.ImageFolder(root=data_dir, transform=train_transform)\n",
        "\n",
        "# Membagi dataset (80% training, 20% validation)\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Menetapkan transformasi yang berbeda untuk data validasi\n",
        "val_dataset.dataset.transform = val_transform\n",
        "\n",
        "# DataLoader untuk training dan validation\n",
        "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=False, num_workers=2)\n",
        "\n",
        "# Verifikasi jumlah data\n",
        "print(f\"Jumlah data training: {len(train_loader.dataset)}\")\n",
        "print(f\"Jumlah data validation: {len(val_loader.dataset)}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hh69LrCYNpk",
        "outputId": "06f07f04-03e8-4164-a45f-c5a296034c23"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data training: 1592\n",
            "Jumlah data validation: 399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan nama kelas dalam dataset\n",
        "print(\"Kelas yang ada dalam dataset:\", full_dataset.classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxRrTJqKdmyr",
        "outputId": "a87dfee9-6ac0-4b1d-f2fc-a1ad7796e895"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kelas yang ada dalam dataset: ['Straight', 'Wavy', 'curly', 'dreadlocks', 'kinky']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan jumlah gambar dalam dataset\n",
        "print(\"Total gambar dalam dataset:\", len(full_dataset))\n",
        "\n",
        "# Melihat contoh data (gambar pertama)\n",
        "image, label = full_dataset[0]\n",
        "print(\"Label gambar pertama:\", label)\n",
        "print(\"Ukuran tensor gambar pertama:\", image.shape)  # Ukuran gambar (misalnya, [3, 128, 128] untuk RGB)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIQhDBXteLb6",
        "outputId": "271984a7-20ff-41e8-eba2-a727caa21d70"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total gambar dalam dataset: 1991\n",
            "Label gambar pertama: 0\n",
            "Ukuran tensor gambar pertama: torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class HairTypeClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=5):  # num_classes = jumlah kelas dalam dataset Anda\n",
        "        super(HairTypeClassifier, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Pooling layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 28 * 28, 256)  # Sesuaikan ukuran input sesuai ukuran gambar setelah konvolusi\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, num_classes)\n",
        "\n",
        "        # Dropout layer untuk regularisasi\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers dengan ReLU dan pooling\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "\n",
        "        # Flattening layer\n",
        "        x = x.view(x.size(0), -1)  # Sesuaikan dengan ukuran gambar setelah konvolusi dan pooling\n",
        "\n",
        "        # Fully connected layers dengan Dropout dan ReLU\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Output layer\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Inisialisasi model\n",
        "num_classes = 5\n",
        "model = HairTypeClassifier(num_classes=num_classes)\n",
        "\n",
        "# Menampilkan arsitektur model\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZuV7AOze7vy",
        "outputId": "f6cebedd-d5cb-4fed-9e47-0cbfc8caf87f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HairTypeClassifier(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=100352, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=5, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Loss function dan optimizer\n",
        "model=model\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "\n",
        "# Jika Anda ingin melatih model pada GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "aG-2SmqGfrei"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SneiqTlsvP_u"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pastikan semua bagian dari kode sebelumnya sudah di-define\n",
        "\n",
        "# Menginisialisasi model\n",
        "num_classes = 5\n",
        "model = HairTypeClassifier(num_classes=num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function dan optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "\n",
        "# Fungsi untuk pelatihan model\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=40):\n",
        "    best_val_accuracy = 0.0\n",
        "    early_stopping_counter = 0\n",
        "    patience = 5  # Berapa epoch yang diizinkan tanpa perbaikan\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model ke mode training\n",
        "        running_loss = 0.0\n",
        "\n",
        "        # Training phase\n",
        "        for inputs, labels in tqdm(train_loader, desc=f'Training Epoch {epoch + 1}/{num_epochs}'):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        print(f'Train Loss: {epoch_loss:.4f}')\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval()  # Set model ke mode evaluasi\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in tqdm(val_loader, desc=f'Evaluating Epoch {epoch + 1}/{num_epochs}'):\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_accuracy = correct / total\n",
        "        epoch_val_loss = val_loss / len(val_loader)\n",
        "        print(f'Validation Loss: {epoch_val_loss:.4f}, Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "        # Early stopping check\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            early_stopping_counter = 0  # Reset counter\n",
        "            # Save your model here if desired\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "            if early_stopping_counter >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "# Memanggil fungsi pelatihan\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY6OIy2bviYf",
        "outputId": "d604afac-7ef2-4604-d8c9-eb106ef03165"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1/40: 100%|██████████| 50/50 [00:19<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.5996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 1/40: 100%|██████████| 13/13 [00:04<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.5286, Accuracy: 0.3358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 2/40: 100%|██████████| 50/50 [00:17<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.5265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 2/40: 100%|██████████| 13/13 [00:03<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.4565, Accuracy: 0.3434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 3/40: 100%|██████████| 50/50 [00:16<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.4687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 3/40: 100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.3839, Accuracy: 0.3885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 4/40: 100%|██████████| 50/50 [00:16<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.4091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 4/40: 100%|██████████| 13/13 [00:03<00:00,  3.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.2830, Accuracy: 0.4536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 5/40: 100%|██████████| 50/50 [00:17<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.3414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 5/40: 100%|██████████| 13/13 [00:04<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.2900, Accuracy: 0.4536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 6/40: 100%|██████████| 50/50 [00:18<00:00,  2.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.2215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 6/40: 100%|██████████| 13/13 [00:03<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.2019, Accuracy: 0.5313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 7/40: 100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 7/40: 100%|██████████| 13/13 [00:03<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1840, Accuracy: 0.5163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 8/40: 100%|██████████| 50/50 [00:17<00:00,  2.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.8912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 8/40: 100%|██████████| 13/13 [00:04<00:00,  2.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.2537, Accuracy: 0.5013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 9/40: 100%|██████████| 50/50 [00:17<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 9/40: 100%|██████████| 13/13 [00:03<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.2788, Accuracy: 0.5213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 10/40: 100%|██████████| 50/50 [00:17<00:00,  2.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 10/40: 100%|██████████| 13/13 [00:05<00:00,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.4374, Accuracy: 0.5113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 11/40: 100%|██████████| 50/50 [00:17<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 11/40: 100%|██████████| 13/13 [00:03<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.5560, Accuracy: 0.5539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 12/40: 100%|██████████| 50/50 [00:17<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 12/40: 100%|██████████| 13/13 [00:04<00:00,  2.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.7371, Accuracy: 0.5439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 13/40: 100%|██████████| 50/50 [00:17<00:00,  2.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 13/40: 100%|██████████| 13/13 [00:03<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.7661, Accuracy: 0.5338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 14/40: 100%|██████████| 50/50 [00:17<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 14/40: 100%|██████████| 13/13 [00:04<00:00,  2.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.9220, Accuracy: 0.5288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 15/40: 100%|██████████| 50/50 [00:18<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 15/40: 100%|██████████| 13/13 [00:03<00:00,  3.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.0861, Accuracy: 0.5088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 16/40: 100%|██████████| 50/50 [00:17<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 16/40: 100%|██████████| 13/13 [00:03<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.0174, Accuracy: 0.5739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 17/40: 100%|██████████| 50/50 [00:18<00:00,  2.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 17/40: 100%|██████████| 13/13 [00:04<00:00,  3.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.0192, Accuracy: 0.5589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 18/40: 100%|██████████| 50/50 [00:17<00:00,  2.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 18/40: 100%|██████████| 13/13 [00:03<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.2856, Accuracy: 0.5363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 19/40: 100%|██████████| 50/50 [00:17<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 19/40: 100%|██████████| 13/13 [00:05<00:00,  2.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.2518, Accuracy: 0.5539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 20/40: 100%|██████████| 50/50 [00:19<00:00,  2.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 20/40: 100%|██████████| 13/13 [00:03<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.0441, Accuracy: 0.5714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 21/40: 100%|██████████| 50/50 [00:17<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Epoch 21/40: 100%|██████████| 13/13 [00:05<00:00,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.0354, Accuracy: 0.5514\n",
            "Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}